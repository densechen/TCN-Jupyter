{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copying Memory Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this task, each input sequence has length T+20. The first 10 values are chosen randonly among the digits 1-8, with the rest being all zeros, except for the last 11 entries that are filled with the digits '9' (the first '9' is a delimiter). The goal is to generate an output of same length that is zero everywhere, except the last 10 values after the delimier, where the model is excepted to repeat the 10 values it encountered at the start of the input.\n",
    "\n",
    "**NOTE**: Because a TCN's receptive fields depends on depth of the network and the filter size, we need to make sure the model we use can cover the sequence length T+20. Using the `seq_len` flag, one can change the # of values to recall(the typical setup is 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f773c0999b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = \"cpu\"\n",
    "DROPOUT = 0.0\n",
    "CLIP = 1.0\n",
    "EPOCHS = 5\n",
    "KSIZE = 8\n",
    "ITERS = 100\n",
    "LEVELS = 8\n",
    "BLANK_LEN = 10000\n",
    "SEQ_LEN = 10\n",
    "LR = 5e-4\n",
    "OPTIM = \"Adam\"\n",
    "NHID = 10\n",
    "SEED = 1111\n",
    "\n",
    "T = BLANK_LEN\n",
    "N_STEPS = T + (2 * SEQ_LEN)\n",
    "N_CLASSES = 10\n",
    "N_TRAIN = 10000\n",
    "N_TEST = 1000\n",
    "\n",
    "CHANNEL_SIZES = [NHID] * LEVELS\n",
    "\n",
    "th.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing data...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "def data_generator(b_size):\n",
    "    \"\"\"Generate data for the copying memory task.\n",
    "    \n",
    "    :param T: the total blank time length.\n",
    "    :param mem_length: the length of the memory to be recalled.\n",
    "    :param b_size: the batch size.\n",
    "    \"\"\"\n",
    "    seq = th.from_numpy(np.random.randint(1, 9, size=(b_size, SEQ_LEN))).float()\n",
    "    zeros = th.zeros((b_size, T))\n",
    "    marker = 9 * th.ones((b_size, SEQ_LEN + 1))\n",
    "    place_holders = th.zeros((b_size, SEQ_LEN))\n",
    "    \n",
    "    x = th.cat((seq, zeros[:, :-1], marker), 1)\n",
    "    y = th.cat((place_holders, zeros, seq), 1).long()\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "print(\"Producing data...\")\n",
    "train_x, train_y = data_generator(N_TRAIN)\n",
    "test_x, test_y = data_generator(N_TEST)\n",
    "\n",
    "train_x, train_y = train_x.to(DEVICE), train_y.to(DEVICE)\n",
    "test_x, test_y = test_x.to(DEVICE), test_y.to(DEVICE)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "from core.tcn import TemporalConvNet\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super().__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y1 = self.tcn(x)\n",
    "        return self.linear(y1.transpose(1, 2))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = TCN(1, N_CLASSES, CHANNEL_SIZES, KSIZE, dropout=DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = getattr(th.optim, OPTIM)(model.parameters(), lr=LR)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f23f4de7018439d80b6620619e246bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.9125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a650c5eaf3cf4abbb54d1327c2fadfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.9124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac8eb4e25984657ac3d234d1a01c98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.9122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f86488697e847ccb4a87f84096b991e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.9125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358da6a32f514123b06511f5c1ef57a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.9124\n"
     ]
    }
   ],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        out = model(test_x.unsqueeze(1).contiguous())\n",
    "        pred = out.view(-1, N_CLASSES).data.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(test_y.data.view_as(pred)).cpu().sum()\n",
    "        counter = out.view(-1, N_CLASSES).size(0)\n",
    "    print(f'Accuracy: {100. * correct / counter:.4f}')\n",
    "\n",
    "def train(ep):\n",
    "    model.train()\n",
    "    process = tqdm(range(0, N_TRAIN, BATCH_SIZE))\n",
    "    for batch in process:\n",
    "        start_ind = batch\n",
    "        end_ind = start_ind + BATCH_SIZE\n",
    "\n",
    "        x = train_x[start_ind:end_ind]\n",
    "        y = train_y[start_ind:end_ind]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(x.unsqueeze(1).contiguous())\n",
    "        loss = F.cross_entropy(out.view(-1, N_CLASSES), y.view(-1))\n",
    "        pred = out.view(-1, N_CLASSES).data.max(1, keepdim=True)[1]\n",
    "        if CLIP > 0:\n",
    "            th.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        process.set_description(f\"Train Epoch: {ep:2d}, loss: {loss.item():.6f}\")\n",
    "\n",
    "for ep in range(1, EPOCHS + 1):\n",
    "    train(ep)\n",
    "    evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
