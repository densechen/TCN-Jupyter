{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Adding Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this task, each input consists of a sequence with shape $T \\times 2$.\n",
    "\n",
    "The first element of sequence is randomly chosen from $[0, 1]$.\n",
    "The second element of sequence consists of all zeros expect for two elements, which are marked by 1.\n",
    "\n",
    "The objective is to sum the two random values whose second elements are marked by 1. \n",
    "One can think of this as computing the dot product of two dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f66f99a8510>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda:0\"\n",
    "DROPOUT = 0.0\n",
    "CLIP = -1.0\n",
    "EPOCHS = 10\n",
    "KSIZE = 7\n",
    "LEVELS = 8\n",
    "SEQ_LEN = 400\n",
    "LR = 4e-3\n",
    "OPTIM = \"Adam\"\n",
    "NHID = 30\n",
    "SEED = 1111\n",
    "\n",
    "INPUT_CHANNELS = 2\n",
    "N_CLASSES = 1\n",
    "\n",
    "CHANNEL_SIZES = [NHID] * LEVELS\n",
    "\n",
    "th.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing data...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "def data_generator(N: int):\n",
    "    \"\"\"\n",
    "    :param N: number of data in the set.\n",
    "    \"\"\"\n",
    "    x_num = th.rand([N, 1, SEQ_LEN])\n",
    "    x_mask = th.zeros([N, 1, SEQ_LEN])\n",
    "    y = th.zeros([N, 1])\n",
    "    for i in range(N):\n",
    "        first, second = np.random.choice(SEQ_LEN, size=2, replace=False)\n",
    "        x_mask[i, 0, first] = 1\n",
    "        x_mask[i, 0, second] = 1\n",
    "        y[i, 0] = x_num[i, 0, first] + x_num[i, 0, second]\n",
    "    x = th.cat([x_num, x_mask], dim=1) # N, 2, SEQ_LEN\n",
    "    return x, y\n",
    "\n",
    "print(\"Producing data...\")\n",
    "x_train, y_train = data_generator(50000)\n",
    "x_test, y_test = data_generator(1000)\n",
    "x_train, y_train = x_train.to(DEVICE), y_train.to(DEVICE)\n",
    "x_test, y_test = x_test.to(DEVICE), y_test.to(DEVICE)\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model Size: 96.001 K\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "from core.tcn import TemporalConvNet\n",
    "import torch.nn as nn\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
    "        super().__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.tcn(x)\n",
    "        return self.linear(y[..., -1])\n",
    "\n",
    "# define model\n",
    "print(\"Building model...\")\n",
    "model = TCN(INPUT_CHANNELS, N_CLASSES, CHANNEL_SIZES, kernel_size=KSIZE, dropout=DROPOUT)\n",
    "model = model.to(DEVICE)\n",
    "optimizer = getattr(th.optim, OPTIM)(model.parameters(), lr=LR)\n",
    "\n",
    "model_size = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"Model Size: {model_size/1000} K\")\n",
    "print(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "\n",
    "**NOTE**: Simply predicting the sum to be 1 will give a MSE about 0.1767."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a200c10964e4d17bd4d2d902152c13e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.177002\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e7505d167040ed8d5f9238c30d75ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.175263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29df71fb20a8414696d5e7150c0ac82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.173659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a737bac3f7d4a989547eda9796b05da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.002255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6081d81dbe40fca10a479f3883fc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.000805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018564fe03c84ee2ad80451383cb509f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.000562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c800ab4413f469da6a516d4614b798b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.000519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59639171a2164f088eed2d404eca5c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.000785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7c6d1f0c90481b9a30442f3c498366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.000349\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1580e14f8b5e4f8d9d862f48215955c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.002587\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    process = tqdm(range(0, len(x_train), BATCH_SIZE))\n",
    "    \n",
    "    for i in process:\n",
    "        if i + BATCH_SIZE > len(x_train):\n",
    "            x, y = x_train[i:], y_train[i:]\n",
    "        else:\n",
    "            x, y = x_train[i:i+BATCH_SIZE], y_train[i:i+BATCH_SIZE]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = F.mse_loss(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        if CLIP > 0:\n",
    "            th.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        process.set_description(f'Train Epoch: {epoch:2d} Loss: {loss.item():.6f}')\n",
    "\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        output = model(x_test)\n",
    "        test_loss = F.mse_loss(output, y_test)\n",
    "        print(f'Test set: Average loss: {test_loss.item():.6f}')\n",
    "        return test_loss.item()\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    train(ep)\n",
    "    tloss = evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
